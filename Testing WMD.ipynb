{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/squad/train-v1.1.json') as json_data:\n",
    "    train_data = json.load(json_data)\n",
    "with open('data/squad/dev-v1.1.json') as json_data:\n",
    "    dev_data = json.load(json_data)\n",
    "train_data['data'].extend(dev_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "all_question = []\n",
    "full_paragraph= []\n",
    "paragraph_question = []\n",
    "paragraph_answer = []\n",
    "all_answer = []\n",
    "for data_index, data_paragraph in enumerate(train_data['data']):\n",
    "    context = []\n",
    "    question = []\n",
    "    ans = []\n",
    "    for each_paragraph in data_paragraph['paragraphs']:\n",
    "            question_data = each_paragraph['qas']\n",
    "            context_data = each_paragraph['context']\n",
    "            context.append(sent_tokenize(context_data))\n",
    "            for number_of_question in range(len(question_data)):\n",
    "                question.append(question_data[number_of_question]['question'])\n",
    "                start_index = question_data[number_of_question]['answers'][0]['answer_start']\n",
    "                answer = question_data[number_of_question]['answers'][0]['text']\n",
    "                end_index = start_index + len(answer)\n",
    "                full_stop = []\n",
    "                for pos,char in zip(range(len(context_data)),context_data):\n",
    "                    if char == '.':\n",
    "                        full_stop.append(pos)\n",
    "                full_stop.append(start_index)\n",
    "                full_stop = sorted(full_stop)\n",
    "                for pos,value in enumerate(full_stop):\n",
    "                    if value == start_index:\n",
    "                        if pos == 0:\n",
    "                            answer_start = pos\n",
    "                        else:\n",
    "                            answer_start = full_stop[pos - 1] + 2\n",
    "                        if pos == len(full_stop) - 1:\n",
    "                            answer_stop = pos\n",
    "                        else:\n",
    "                            answer_stop = full_stop[pos + 1] \n",
    "                ans.append(context_data[answer_start:answer_stop])\n",
    "    paragraph_question.append(question)       \n",
    "    full_paragraph.append(context)\n",
    "    paragraph_answer.append(ans)\n",
    "    context = []\n",
    "    question = []\n",
    "    ans = []\n",
    "data.append(full_paragraph)\n",
    "all_question.append(paragraph_question)\n",
    "all_answer.append(paragraph_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = []\n",
    "all_sent = []\n",
    "for each_paragraph in data[0]:\n",
    "    for each_context in each_paragraph:\n",
    "        for each_sent in each_context:\n",
    "            sent.append(each_sent)\n",
    "    all_sent.append(sent)\n",
    "    sent = []\n",
    "all_ques,ques = [],[]\n",
    "for paragraph_question in all_question[0]:\n",
    "    for each_question in paragraph_question:\n",
    "        ques.append(each_question)\n",
    "    all_ques.append(ques)\n",
    "    ques = []\n",
    "all_ans,ans = [],[]\n",
    "for paragraph_answer in all_answer[0]:\n",
    "    for each_answer in paragraph_answer:\n",
    "        ans.append(each_answer)\n",
    "    all_ans.append(ans)\n",
    "    ans = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ques_ans_sent = pd.DataFrame({'sent':all_sent,'ans':all_ans,'ques':all_ques})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMD = []\n",
    "sentence = []\n",
    "for sent in all_sent[0]:\n",
    "    for ques in all_ques[0]:\n",
    "        wmd_tag = get_wmd_for_tags_test(ques,sent)\n",
    "        wmd_glove = get_emd(ques,sent)\n",
    "        EMD.append((wmd_tag,wmd_glove))\n",
    "        sentence.append(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
